<tool id="dataset-exporter" name="Dataset Exporter" version="0.6.0" profile="18.01">
    <description>- transfer datasets to network shares</description>
    <requirements>
    </requirements>
    <macros>
        <import>predefined_export_paths.xml</import>
        <token name="@resolve_tags_for_dataset@">
            #set taglist = []
            #for $t in $dataset.tags:
                #if $t.user_tname == 'name':
                    #set taglist = taglist + [t.user_value]
                #else:
                    #set taglist = taglist + [t.user_tname]
                #end if
            #end for
            #set tags = ','.join(taglist)
        </token>
    </macros>
    <command detect_errors="exit_code"><![CDATA[
        #set is_admin = $__user_email__ in $__admin_users__
        python '$__tool_directory__/dataset_export.py'
            --email '$__user_email__'
            --username '$__user_name__'

            #if $collection:
                #for $d in $collection:
                    #if hasattr($d, "tags"):
                        #set dataset = d
                        @resolve_tags_for_dataset@
                        --dataset '${d}'
                        --dataset_name '${d.element_identifier}'
                        --dataset_extension '${d.ext}'
                        --dataset_extra_files '${d.extra_files_path}'
                        --collection_name '${collection.element_identifier}'
                        --dataset_tags '${tags}'
                        --history_id '${d.hid}'
                        --history_name '${d.dataset.history.name}'
                    #elif hasattr($d, "forward"):
                        ## this is most probably a collection with a list of pairs
                        ## so we just repeat this block..
                        #set dataset = d.forward
                        @resolve_tags_for_dataset@
                        --dataset '${d.forward}'
                        --dataset_name '${d.element_identifier}_${d.forward.element_identifier}'
                        --dataset_extension '${d.forward.ext}'
                        --dataset_extra_files '${d.forward.extra_files_path}'
                        --collection_name '${collection.element_identifier}'
                        --dataset_tags '${tags}'
                        --history_id '${d.forward.hid}'
                        --history_name '${d.forward.dataset.history.name}'

                        #set dataset = d.reverse
                        @resolve_tags_for_dataset@
                        --dataset '${d.reverse}'
                        --dataset_name '${d.element_identifier}_${d.reverse.element_identifier}'
                        --dataset_extension '${d.reverse.ext}'
                        --dataset_extra_files '${d.reverse.extra_files_path}'
                        --collection_name '${collection.element_identifier}'
                        --dataset_tags '${tags}'
                        --history_id '${d.reverse.hid}'
                        --history_name '${d.reverse.dataset.history.name}'
                    #end if
                #end for
            #end if
            #if $datasets:
                #for $dataset in $datasets
                    @resolve_tags_for_dataset@
                    --dataset '${dataset}'
                    --dataset_name '${dataset.element_identifier}'
                    --dataset_extension '${dataset.ext}'
                    --dataset_extra_files '${dataset.extra_files_path}'
                    --collection_name ''
                    --dataset_tags '${tags}'
                    --history_id '${dataset.hid}'
                    --history_name '${dataset.dataset.history.name}'
                #end for
            #end if

            #if str( $options.selection_mode ) == "defaults":
                --file_pattern '${options.predefined_file_pattern}'
            #else:
                --file_pattern '${options.file_pattern}'
                #if $options.copy_extra_files:
                    --copy_extra_files
                #end if
            #end if
            --log '$log'
            #if $is_admin:
                --skip_user_permission_check
            #end if
            #if $dry_run:
                --dry_run
            #end if
            #if $primary_group:
                --run_with_primary_group
            #end if
            #if $export_metadata:
                --export_metadata
            #end if

    ]]></command>
    <inputs>
        <param name="datasets" type="data" format="data" multiple="true" label="Datasets to export" optional="true"
               help="Select one or more datasets to export. Or select a collection below!"/>
        <param name="collection" type="data_collection" format="data" label="Collection to export" optional="true"
               help="Select a collection to export, you can use the name of the collection through the {collection}
               placeholder in the file pattern below."/>
        <conditional name="options">
            <param label="Use advanced options" name="selection_mode" type="select">
              <option selected="true" value="defaults">Use default options</option>
              <option value="advanced">Use advanced options</option>
            </param>
            <when value="defaults">
                <expand macro="@predefined_export_paths@"/>
            </when>
            <when value="advanced">
                <param name="file_pattern" type="text" label="File pattern (see below for placeholders}"
                       help="Where the file needs to placed and how the name should be constructed."
                       value="/scratch/{username}/{history}/{name}_{tags}.{ext}">
                            <validator type="empty_field" />
                            <sanitizer sanitize="false" />
                </param>
                <param name="copy_extra_files" type="boolean" checked="False"
                       label="Also copy extra files belonging to this dataset"
                       help="This will create a directory (File Pattern + '_files') and copy all files there.
                       Generally only needed for html reports that do not include all the images"/>
            </when>
        </conditional>
        <param name="primary_group" type="boolean" label="Try to create directory and files with your primary group" checked="true"
               help="Generally this is the recommend option. If you uncheck this, galaxy will export files with the permissive 777."/>
        <param name="export_metadata" type="boolean" label="Export a metadata file for every dataset" checked="false"
               help="File will be named {dataset}.info next to the exported dataset."/>
        <param name="dry_run" type="boolean" label="Only do a dry run" checked="false"
               help="No directories will be created or files written! Very useful to find the right pattern!"/>
    </inputs>
    <outputs>
        <data name="log" format="txt" />
    </outputs>
    <help><![CDATA[

        @help_macro@

        **File Pattern** Available placeholders are:

            - {username}: your username
            - {email}: your email address
            - {group}: your **primary** unix group
            - {id}: Dataset id
            - {name}: Dataset name
            - {ext}: Dataset extension (e.g. bam, fa)
            - {collection}: Collection name, **only available** for 'Collection to export' inputs. Will be ignored otherwise.
            - {history}: history name
            - {tags}: all tags on the dataset separated by a dash e.g. myfasta_tag1-tag2.fa
            - {tag:<name>}: only use the value of the tag named '<name>', e.g. a dataset  `SeqX_from_PMID_{tag:PMID}.fa` with the tag `#PMID:23002` becomes `SeqX_from_PMID_23002.fa`
            - {hid}: Galaxy history id

            E.g. "/g/{group}/{username}/{history}/{name}_{tags}.{ext}" will become: "/g/gbcs/scholtal/My_History/myfasta_tag1-tag2.fa"

        **Note:** File paths cannot contain any whitespaces, they will be converted to underscores(_)
    ]]></help>
</tool>
